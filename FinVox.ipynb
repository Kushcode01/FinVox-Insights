{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ts4Rg3orkuk"
      },
      "source": [
        "## FinVox Insights\n",
        "#### FinVox Insights is POC voice based financial data visualization tool. The tool integrates **GPT 3.5** for URL generation which is passed to **Alphavantage** API to fetch the financial data. The visulization techniques includes interactive scatter plots, 3-D plots with option to pan, zoom, lasso select certian data points. The tool is complete with frontend developed using **Gradio.io**\n",
        "\n",
        "\n",
        "## Intalling necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EJ9IuGNBrCNJ",
        "outputId": "8a6ec878-f209-4487-beff-6903436ffa57"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install plotly\n",
        "!pip install ffmpeg-python\n",
        "!pip install mplfinance\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T323_M3hm0O"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qM2PgJ3nuRgA"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import mplfinance as mpf\n",
        "import matplotlib.dates as mdates\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA7H-ENSqgqp",
        "outputId": "1bcff858-71fe-4fe8-c3fe-7210db359948"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-16 01:22:18,277 - __main__ - INFO - Logging is configured and the script has started.\n"
          ]
        }
      ],
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "                    handlers=[\n",
        "                        logging.FileHandler(\"app.log\"),\n",
        "                        logging.StreamHandler()\n",
        "                    ],\n",
        "                    force=True)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "logger.info(\"Logging is configured and the script has started.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmKRGNzrhubt"
      },
      "source": [
        "## Defining helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9kwZs1HBggcM"
      },
      "outputs": [],
      "source": [
        "def set_openAIKey():\n",
        "  openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Function to normalize keys\n",
        "def normalize_keys(d):\n",
        "    new_dict = {}\n",
        "    for key, value in d.items():\n",
        "        # Normalize key to lowercase and remove underscores\n",
        "        new_key = key.lower().replace('_', '')\n",
        "        new_dict[new_key] = value\n",
        "    return new_dict\n",
        "\n",
        "# Function to extract string portion from column names\n",
        "def extract_string(column_name):\n",
        "    parts = column_name.split('. ')\n",
        "    if len(parts) > 1:\n",
        "        return parts[1]\n",
        "    else:\n",
        "        return column_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYJRsfWEh47i"
      },
      "source": [
        "## Prompt Engineering : Prompting the model to obtain relevant data for AlphaVantage API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9Q0EPUQzhzFp"
      },
      "outputs": [],
      "source": [
        "def get_URL(user_input):\n",
        "\n",
        "  prompt = f'''\n",
        "    Fetch me the AlphaVantage API URLs, Company names, and function name for the following task-\n",
        "    {user_input} for all companies mentioned in the input, separated by commas, in the format:\n",
        "    Company Names: [Company 1, Company 2, ...]\n",
        "    Function Name:\n",
        "    Api Urls: [Url for Company 1, Url for Company 2, ...]\n",
        "\n",
        "    Additionally, specify if you want to:\n",
        "    - Overlap/Juxtapose the data (True/False):\n",
        "\n",
        "    For example:\n",
        "    If the task is to fetch balance sheet for Google (GOOG) and Microsoft (MSFT) and overlap the data:\n",
        "    Company Names: [Google, Microsoft]\n",
        "    Overlap/Juxtapose: True\n",
        "    Function Name: Balance Sheet\n",
        "    Api Urls: [https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol=GOOG&apikey=YOUR_API_KEY, https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol=MSFT&apikey=YOUR_API_KEY]\n",
        "\n",
        "    Strictly follow the format for your response.\n",
        "    '''\n",
        "\n",
        "\n",
        "  client = OpenAI()\n",
        "\n",
        "  try:\n",
        "\n",
        "      response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "      )\n",
        "\n",
        "      logger.info(f\"Response from OpenAI: {response}\")\n",
        "\n",
        "      if response.choices and response.choices[0].message.content:\n",
        "          json_string = response.choices[0].message.content.strip(\"\")\n",
        "          s = json.loads(json_string)\n",
        "          # Normalize keys in the dictionary\n",
        "          normalized_data = normalize_keys(s)\n",
        "          return normalized_data\n",
        "\n",
        "      else:\n",
        "          raise ValueError(\"Invalid response received from OpenAI API.\")\n",
        "  except Exception as e:\n",
        "      logger.error(f\"An error occurred during data retrieval: {str(e)}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "def get_data(response_url, function_name, company_name):\n",
        "\n",
        "  api_key = userdata.get('AVANTAGE_API_KEY')\n",
        "\n",
        "  # Dynamically add API key and other parameters to the API URL\n",
        "  api_url = response_url.replace(\"YOUR_API_KEY\", api_key)\n",
        "  logging.info(f\"Fetching data from URL: {api_url}\")\n",
        "\n",
        "  response = requests.get(api_url)\n",
        "\n",
        "  data = response.json()\n",
        "\n",
        "  logging.info(f\"Function name: {function_name}\")\n",
        "\n",
        "\n",
        "\n",
        "# Handle Time Series data differently for visualisation\n",
        "\n",
        "  if 'Time Series' in function_name:\n",
        "\n",
        "    # Convert dictionary to list of key-value pairs\n",
        "    pairs = list(data.items())\n",
        "\n",
        "    # Get the second key-value pair\n",
        "    second_pair = pairs[1]\n",
        "\n",
        "    # Access key and value separately\n",
        "    second_key, second_value = second_pair\n",
        "\n",
        "    # Convert dictionary to DataFrame\n",
        "    df = pd.DataFrame.from_dict(second_value, orient='index')\n",
        "\n",
        "    # Reset index to make 'Date' a column\n",
        "    df.reset_index(inplace=True)\n",
        "    df.rename(columns={'index': 'Date'}, inplace=True)\n",
        "\n",
        "    df.columns = [extract_string(col) for col in df.columns]\n",
        "\n",
        "    # Set 'Date' as index\n",
        "    df.set_index('Date', inplace=True)\n",
        "\n",
        "    # Convert data types\n",
        "    df = df.astype(float)  # Convert numerical columns to float if necessary\n",
        "\n",
        "    # st.write(df.head())\n",
        "\n",
        "    csv_path = f'{company_name}.csv'\n",
        "    df.to_csv(csv_path)\n",
        "    logger.info(f\"CSV file saved successfully at {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhQXDEDsmXDH"
      },
      "source": [
        "## Defining functions for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T4etWYnKGpS8"
      },
      "outputs": [],
      "source": [
        "# Function to plot overlapping time series\n",
        "def plot_overlapping_time_series(company_list):\n",
        "  fig, ax = plt.subplots()\n",
        "  for company in company_list:\n",
        "      df = pd.read_csv(f'{company}.csv')\n",
        "      y_axis = 'close'\n",
        "      ax.plot(df['Date'], df[y_axis], label=company)\n",
        "\n",
        "  ax.set_xlabel('Date')\n",
        "  ax.set_ylabel('Value')\n",
        "  ax.set_title('Time Series')\n",
        "  n = 5\n",
        "  ax.set_xticks(ax.get_xticks()[::n])\n",
        "  plt.xticks(rotation=90)\n",
        "  ax.legend()\n",
        "\n",
        "  return fig\n",
        "\n",
        "\n",
        "def plot_time_series_single(time_series_df):\n",
        "\n",
        "  # Create a candlestick chart\n",
        "  fig = go.Figure(data=[go.Candlestick(x=time_series_df['Date'],\n",
        "                                      open=time_series_df['open'],\n",
        "                                      high=time_series_df['high'],\n",
        "                                      low=time_series_df['low'],\n",
        "                                      close=time_series_df['close'])])\n",
        "\n",
        "  # Update layout for better visualization\n",
        "  fig.update_layout(title='Candlestick Chart',\n",
        "                    xaxis_title='Date',\n",
        "                    yaxis_title='Price',\n",
        "                    xaxis_rangeslider_visible=True)\n",
        "\n",
        "  return fig\n",
        "\n",
        "\n",
        "def plot_graph(function_name, company_names):\n",
        "  if 'Time Series' in function_name:\n",
        "\n",
        "    number_of_companies = len(company_names)\n",
        "\n",
        "    if number_of_companies == 1:\n",
        "      stock_data = pd.read_csv(f'{company_names[0]}.csv')\n",
        "      return plot_time_series_single(stock_data)\n",
        "\n",
        "    else:\n",
        "      return plot_overlapping_time_series(company_names)\n",
        "\n",
        "  else:\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG16iz-lmbXS"
      },
      "source": [
        "## Visualization of the data on Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "NMBhkGugubyD",
        "outputId": "3b35432c-9fd8-4afb-eb2f-07f7d50cedf1"
      },
      "outputs": [],
      "source": [
        "# Placeholder function for visualization (replace with your logic)\n",
        "def visualize(text):\n",
        "  visualization = \"This is a placeholder for visualization\"\n",
        "  set_openAIKey()\n",
        "  response_dict = get_URL(text)\n",
        "\n",
        "  for i in range(len(response_dict['company names'])):\n",
        "    get_data(response_dict['api urls'][i], response_dict['function name'], response_dict['company names'][i])\n",
        "\n",
        "  fig = plot_graph(response_dict['function name'],response_dict['company names'])\n",
        "  return fig\n",
        "\n",
        "\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
        "\n",
        "\n",
        "def transcribe(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "\n",
        "    output = transcriber({\"sampling_rate\": sr, \"raw\": y})\n",
        "    text = output[\"text\"]\n",
        "    logger.info(f\"Transcribed text: {text}\")\n",
        "    visualization_data = visualize(text)  # Call the visualization function\n",
        "    return text, visualization_data\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Audio Transcription and Visualization\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_input = gr.Audio(sources=[\"microphone\"], label=\"Record your audio\")\n",
        "            transcribe_button = gr.Button(\"Transcribe and Visualize\")\n",
        "\n",
        "        with gr.Column():\n",
        "            transcription_output = gr.Textbox(label=\"Transcription\")\n",
        "            visualization_output = gr.Plot()\n",
        "\n",
        "    transcribe_button.click(\n",
        "        transcribe,\n",
        "        inputs=audio_input,\n",
        "        outputs=[transcription_output, visualization_output]\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rpxZ5B68qzhN",
        "XMy4Cy2Eqlg6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
